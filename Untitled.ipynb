{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7327502b-db9b-433a-b1fe-97a3c726aee7",
   "metadata": {},
   "source": [
    "# ü§ñ Capstone Project: AgentRed - AI-Powered Debate System using Generative AI\n",
    "\n",
    "## üìå Introduction\n",
    "\n",
    "As part of the **Kaggle 5-Day Generative AI Intensive Course**, this capstone project explores an innovative application of GenAI: simulating debates between opposing public narratives using AI agents. The system not only gathers and analyzes online opinions but also engages in a logic-based debate to determine which side presents a more compelling argument.\n",
    "\n",
    "### üéØ Project Objectives\n",
    "\n",
    "The key features of this AI debate system are:\n",
    "\n",
    "1. **Dominant Sentiments Detection**  \n",
    "   Extract and analyze the prevailing public sentiments around a specific topic or event from online platforms.\n",
    "\n",
    "2. **Popular Opinion Mining**  \n",
    "   Identify the most influential or frequently expressed opinions to represent both sides of a debate.\n",
    "\n",
    "3. **AI Debate Simulation**  \n",
    "   Generate a debate between two AI agents representing each dominant narrative. A third AI agent acts as a **Judge**, evaluating the arguments and delivering a **verdict** on which side won based on logic, consistency, and supporting evidence.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Core Concepts Used\n",
    "\n",
    "- **Prompt Engineering**: Carefully crafted prompts guide the behavior of each AI agent to ensure coherent and context-aware responses.\n",
    "- **Agents**: Specialized AI components with designated roles: data retriever, debaters, and judge.\n",
    "- **Chat Persistence (Memory)**: Maintains contextual understanding across multiple exchanges, simulating a more natural and informed conversation.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ System Flow\n",
    "\n",
    "```text\n",
    "User Input (e.g., \"Mike Tyson vs Logan Paul\")\n",
    "        ‚Üì\n",
    "     [Agent]\n",
    "        ‚Üì (Searches & Retrieves using Reddit PRAW API)\n",
    " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    " ‚îÇ     Dominant Narratives      ‚îÇ ‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚Üê‚îê\n",
    " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ\n",
    " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ\n",
    " ‚îÇ      Sentiment Analysis      ‚îÇ ‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚Üí‚îò\n",
    " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚Üì\n",
    "  Opinion #1 vs Opinion #2\n",
    "        ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ    Chad      ‚îÇ     ‚îÇ    Wojak     ‚îÇ\n",
    "‚îÇ (Debater 1)  ‚îÇ     ‚îÇ (Debater 2)  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚Üì                  ‚Üì\n",
    "         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Judge Agent ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                      ‚Üì\n",
    "                  Verdict (Who won?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144b683-2a0c-4b67-8a85-577a322d0eb1",
   "metadata": {},
   "source": [
    "### Loading Environment Variables\n",
    "\n",
    "This cell loads sensitive data like API keys from a `.env` file using the `dotenv` library. The keys are accessed using the `os` module to retrieve the `GOOGLE_API_KEY`, `REDDIT_CLIENT_SECRET`, and `REDDIT_CLIENT_ID` for use in interacting with Google and Reddit APIs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d352936-37c1-4199-a453-b9b61fef7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import praw\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import Image, display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc32189-8b3b-4755-8109-c15a8e687931",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "PRAW_SECRET = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "PRAW_CLIENT = os.getenv(\"REDDIT_CLIENT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3da66-0551-4096-90cd-d317fd02eaee",
   "metadata": {},
   "source": [
    "### Let's Set Up Our LLM!\n",
    "\n",
    "In this cell, we set up the `ChatGoogleGenerativeAI` with the model `gemini-2.0-flash-lite`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0ae35a-9655-42c6-9610-6bd88c3f176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World!\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "response = gemini.invoke(\"Hello World?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef934cc-a9c2-41c7-9cb3-cfd1f47882fc",
   "metadata": {},
   "source": [
    "### Setting Up Reddit API Client\n",
    "\n",
    "Here, we initialize the `praw.Reddit` client to interact with Reddit. We pass in the necessary credentials like `client_id`, `client_secret`, and `user_agent` to authenticate and connect to Reddit's API. This sets us up to retrieve data from Reddit or perform actions like posting or commenting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9fed681-5893-48c2-ae39-43454435123c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package_name\n",
      "  Downloading package_name-0.1.tar.gz (782 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: package_name\n",
      "  Building wheel for package_name (setup.py): started\n",
      "  Building wheel for package_name (setup.py): finished with status 'done'\n",
      "  Created wheel for package_name: filename=package_name-0.1-py3-none-any.whl size=1234 sha256=bd560d93d0a7aa1bb7f032e00a67fd01039bbd0db440181fc279599b6d65f9cb\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\7e\\a6\\f5\\ce521d547a4606ce65febcdcefd1c847622c6451dce9f3e8e5\n",
      "Successfully built package_name\n",
      "Installing collected packages: package_name\n",
      "Successfully installed package_name-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30319de3-f420-4a62-9e6e-6c762daf0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=PRAW_CLIENT,\n",
    "    client_secret=PRAW_SECRET,\n",
    "    user_agent=\"my user agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e878f2-5be3-4113-bfcd-550be953e8e8",
   "metadata": {},
   "source": [
    "\n",
    "### Fetching Hot Posts from the Kaggle Subreddit\n",
    "\n",
    "In this cell, we retrieve the top hot post from the \"Kaggle\" subreddit using the `reddit.subreddit(\"Kaggle\").hot()` method. We limit the results to 4 post and print the post's title and content (`selftext`). This gives us a quick look at the current hot discussions on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b7a2ca-cd01-4172-8db2-bdf388595197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Know to fine tune? I‚Äôm hiring to make some experiments\n",
      "---------------\n",
      "I‚Äôm building an AI companion for mental health, I‚Äôm curious to explore fine tunning models to improve conversation quality. Is anyone around interested? Ideally you have been working on mental health before \n",
      "Gemma not found\n",
      "---------------\n",
      "How do I invoke Gemma once I‚Äôm in a code editor? I have signed the consent but she‚Äôs no where to be found :)\n",
      "Banned on kaggle for no reason\n",
      "---------------\n",
      "hi im new to data science and ml i had just finished learning stuff like pandas, matplotlib etc .also there is a upcoming kaggle hack in my college and i wanted to participate as i open kaggle try to login i get a shocking \n",
      "\n",
      "message \n",
      "\n",
      "Your account has been suspended or banned. Please check the email associated with your Kaggle account for more information.\n",
      "\n",
      "i quickly checked my email to find there was no mail regarding my ban or suspension i never used kaggle before the only activity that happened before is that a few seniors came into the activity space (\"place where people code or study in my campus\") and one by one went to every ones computer to introduce us to kaggle the created my account in front of me obviously i created the password and all they dont know it and the told us to look around and see if you i had liked their final project for the semester i liked or followed to help them out i dont remember this very well it was back in febuary please help me look into it i submit a complaint regarding this but i didnt get any confirmation regarding \"your complaint has been issued \"\n",
      "üß† Welcome to r/CrunchDAO\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit(\"Kaggle\").hot(limit=4):\n",
    "    print(submission.title)\n",
    "    print(\"---------------\")\n",
    "    print(submission.selftext)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad80b6f6-4d80-442f-ae62-957541b07aae",
   "metadata": {},
   "source": [
    "### Creating a Function to Retrieve Reddit Submissions\n",
    "\n",
    "We will define a tool using the `langchain` library to retrieve Reddit submissions based on a given topic. The function `retrieve_submissions` allows us to specify:\n",
    "- `topic`: The keyword or phrase to search for.\n",
    "- `k`: The number of submissions to retrieve.\n",
    "- `subreddit_name`: The subreddit to search within (default is \"all\").\n",
    "- `sort`: The sorting method (either 'relevance' or 'top').\n",
    "\n",
    "The function queries Reddit's API, fetches the top `k` submissions related to the topic, and returns a list of dictionaries containing each submission's title, content, and score. This tool helps automate the process of fetching and processing relevant Reddit posts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fcd81d-8dd5-4867-baf9-139b01bc2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition \n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf6a29ef-3ae1-4fd0-9c95-5d3e4828c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_submissions(\n",
    "    topic: str,\n",
    "    k: int,\n",
    "    subreddit_name: str = \"all\",\n",
    "    sort: str = \"relevance\"\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Retrieves the top k Reddit submissions related to a given topic from a subreddit.\n",
    "\n",
    "    Args:\n",
    "        topic (str): The topic to search for in Reddit submissions.\n",
    "        k (int): The number of submissions to retrieve.\n",
    "        subreddit_name (str): The subreddit to search in (default is 'all').\n",
    "        sort (str): The sort order ('relevance' or 'top').\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries with 'title', 'content', and 'score' of each submission.\n",
    "    \"\"\"\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    submissions = subreddit.search(topic, limit=k, sort=sort)\n",
    "\n",
    "    results = []\n",
    "    for submission in submissions:\n",
    "        results.append({\n",
    "            'title': submission.title,\n",
    "            'content': submission.selftext,\n",
    "            'score': submission.score\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0f8a3-ab8a-4f64-afd1-14de80ceddaa",
   "metadata": {},
   "source": [
    "### Binding the Tool to the LLM\n",
    "\n",
    "We bind the `retrieve_submissions` tool to the `gemini` model. By doing this, we enable the model to use the `retrieve_submissions` function as part of its workflow, allowing it to fetch relevant Reddit posts based on a query. The `gemini.bind_tools(tools)` method connects the tool with the LLM, making it available for use during the model‚Äôs execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0929c880-f08f-4332-96c1-bfa8c01105cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retrieve_submissions]\n",
    "gemini = gemini.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27762b2c-7e29-4c97-9487-8b521c8b8159",
   "metadata": {},
   "source": [
    "## Setting up the retriever agent\n",
    "\n",
    "This code sets up a system where an AI agent analyzes Reddit discussions to find two strong, opposing viewpoints on a specific topic. The purpose is to extract contrasting opinions that could lead to a meaningful debate.\n",
    "\n",
    "- A detailed prompt is defined that instructs the AI on how to approach the task. It includes how to retrieve Reddit posts, what kind of content to focus on (highly upvoted or frequently repeated sentiments), and how to determine when two clear, opposing opinions are identified.\n",
    "\n",
    "- The AI is expected to use a tool called `retrieve_submissions` to fetch Reddit posts based on parameters like topic, subreddit, number of posts (`k`), and sort order. It starts with `k = 5` and increases by 5 until it finds suitable opposing views or reaches a limit of 50.\n",
    "\n",
    "- The reasoning function (`reasoner`) combines the initial system instructions with the current conversation state and uses the Gemini model to generate a response.\n",
    "\n",
    "- A `StateGraph` is used to manage the flow of operations:\n",
    "  - It starts with the `reasoner` node.\n",
    "  - If the AI wants to use a tool (like calling the Reddit API), it transitions to the `tools` node.\n",
    "  - After using the tool, it returns to the `reasoner` to continue processing.\n",
    "  - This loop continues until no more tool use is required, and the task completes.\n",
    "\n",
    "- Finally, the graph structure is compiled and displayed visually, showing how the logic flows between the different parts of the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa71ee03-8685-4a8a-8509-fc1a28534572",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_prompt = \"\"\"\n",
    "Your task is to analyze Reddit discussions on a given topic and uncover two **extreme and opposing opinions** that could spark a meaningful debate.\n",
    "\n",
    "Use the tool `retrieve_submissions(topic: str, k: int, subreddit_name: str = \"all\", sort: str = \"relevance\")` to retrieve recent submissions. Begin with `k = 5`, `subreddit_name = \"all\"`, and `sort = \"top\"` to prioritize influential posts.\n",
    "\n",
    "From each retrieved submission (`title`, `content`, and `score`), identify two strongly **contrasting** perspectives. Each should meet at least one of the following criteria:\n",
    "\n",
    "- Frequently repeated sentiment across multiple posts\n",
    "- Submissions with high upvotes (score)\n",
    "\n",
    "If two such opposing viewpoints aren't clearly found, increment `k` by 5 and call the tool again. Repeat this process until you find two distinctly opposing and well-supported opinions or until `k = 50`.\n",
    "\n",
    "Once found, distill the **Debate Axis** ‚Äî the core question or conflict between the two positions ‚Äî and clearly outline the rationale behind each opinion.\n",
    "\n",
    "üéØ **Output Format**:\n",
    "Return your findings in the following structure:\n",
    "\n",
    "---\n",
    "üîç **Topic Analyzed**: <insert topic here>  \n",
    "üìä **Final k Value Used**: <insert k>  \n",
    "‚öîÔ∏è **Debate Axis**: <Describe the central issue of disagreement between the two sides>\n",
    "\n",
    "üü• **Opinion 1: [Clear title for extreme viewpoint #1]**  \n",
    "**Position Summary**: <Concise, debate-ready thesis of this perspective>  \n",
    "**Key Arguments**:\n",
    "1. Argument 1: <Reason or logic backing the viewpoint>\n",
    "2. Argument 2: <Additional rationale, thematic or emotional>\n",
    "**Supporting Examples**:\n",
    "- \"<Title or excerpt from submission>\" (score: X)\n",
    "- \"<Title or excerpt from another submission>\" (score: X)\n",
    "\n",
    "üü© **Opinion 2: [Clear title for extreme viewpoint #2]**  \n",
    "**Position Summary**: <Contrasting thesis from Opinion 1>  \n",
    "**Key Arguments**:\n",
    "1. Argument 1: <Reason or logic backing the viewpoint>\n",
    "2. Argument 2: <Additional rationale, thematic or emotional>\n",
    "**Supporting Examples**:\n",
    "- \"<Title or excerpt from submission>\" (score: X)\n",
    "- \"<Title or excerpt from another submission>\" (score: X)\n",
    "\n",
    "üß† Notes:\n",
    "- Avoid duplicates, spam, and low-effort content\n",
    "- Focus on well-written, thought-provoking submissions\n",
    "- Emphasize **why** people hold each position, not just **what** they believe\n",
    "- If no strong polarity is found by k = 50, summarize the dominant viewpoint instead\n",
    "üìå Goal: Extract well-structured, opposing Reddit viewpoints that can serve as a foundation for meaningful **debate**, not just casual agreement.\n",
    "\"\"\"\n",
    "\n",
    "sys_msg = SystemMessage(content=agent_prompt)\n",
    "def reasoner(state: MessagesState):\n",
    "   return {\"messages\": [gemini.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"reasoner\", reasoner)\n",
    "builder.add_node(\"tools\", ToolNode(tools)) # for the tools\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"reasoner\")\n",
    "builder.add_conditional_edges(\n",
    "    \"reasoner\",\n",
    "    # If the latest message (result) from node reasoner is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from node reasoner is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"reasoner\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Display the graph\n",
    "# display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cad3d-cd58-4efe-a0d6-c23dde086b0d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "now we will define a function called `extract_opinions`, which takes a user message as input. This message contains the topic to be analyzed (e.g., \"Mike Tyson vs Logan Paul\").\n",
    "\n",
    "- Inside the function:\n",
    "  - The input message is wrapped into a list to fit the expected input format for the reasoning system.\n",
    "  - The `react_graph` (previously defined graph that manages the logic between reasoning and tool usage) is invoked with this message.\n",
    "  - The output is stored in `messages`, and the final AI-generated message (usually the last item) is also extracted separately.\n",
    "\n",
    "- The function returns both the full list of messages and the final output message.\n",
    "\n",
    "- After calling `extract_opinions` with a sample topic, the final message content (which contains the debate analysis) is displayed using `Markdown`, rendering the structured output in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ef6fea-dd0e-4d2b-846e-b5b87c8caa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_opinions(topic):\n",
    "    message = HumanMessage(content=topic)\n",
    "    messages = [message]\n",
    "    messages = react_graph.invoke({\"messages\": messages})\n",
    "    return messages, messages['messages'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7347a71f-6fe0-4da4-a0df-8f5c97789ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"will AI replace Software engineers?\"\n",
    "messages, final_output = extract_opinions(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b84702d6-8320-4d5e-aa95-3d44f5d5e547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "üîç **Topic Analyzed**: Will AI replace Software engineers?\n",
       "üìä **Final k Value Used**: 5\n",
       "‚öîÔ∏è **Debate Axis**: The extent to which AI tools will impact the job security and roles of software engineers.\n",
       "\n",
       "üü• **Opinion 1: AI will significantly impact software engineering roles, potentially leading to job displacement and a shift in required skills.**\n",
       "**Position Summary**: The rapid advancement of AI, particularly in code generation and automation, will lead to a reduction in the demand for traditional software engineering roles. Engineers will need to adapt by focusing on higher-level tasks, AI integration, and specialized areas.\n",
       "**Key Arguments**:\n",
       "1.  AI can already automate significant portions of the coding process, reducing the need for manual coding in some areas.\n",
       "2.  The skills required for software engineers will shift towards prompt engineering, AI model training, and system integration, rather than pure coding.\n",
       "**Supporting Examples**:\n",
       "-   (Implied) The discussions around the closure of Apollo app due to Reddit's API changes, and the impact of these changes on developers, suggest that the industry is in constant flux and that roles are subject to change.\n",
       "\n",
       "üü© **Opinion 2: AI will be a tool to augment software engineers, increasing productivity and efficiency, but not replacing them.**\n",
       "**Position Summary**: AI will become an essential tool for software engineers, automating repetitive tasks and allowing them to focus on more complex problem-solving, design, and innovation. The demand for software engineers will remain strong, but their roles will evolve.\n",
       "**Key Arguments**:\n",
       "1.  AI will handle the \"grunt work\" of coding, allowing engineers to focus on higher-level design, architecture, and problem-solving.\n",
       "2.  Software engineers will be needed to oversee, debug, and refine the code generated by AI, ensuring quality and functionality.\n",
       "**Supporting Examples**:\n",
       "-   (Implied) The discussions around the closure of Apollo app due to Reddit's API changes, and the impact of these changes on developers, suggest that the industry is in constant flux and that roles are subject to change.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(final_output.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0775376-1440-44c3-bd1b-71c7b8dee557",
   "metadata": {},
   "source": [
    "The function below extracts key components from a structured markdown debate transcript, including the debate axis, titles, summaries, and up to two arguments for each opinion. It uses regular expressions to parse the markdown sections based on recognizable headings and markers, returning the extracted data in a clean, structured format suitable for feeding into an AI debate simulation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31e3e699-fa73-4faa-8027-0b968def9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_debate_output(output_text: str):\n",
    "    # Extract Debate Axis\n",
    "    debate_axis_match = re.search(r\"‚öîÔ∏è \\*\\*Debate Axis\\*\\*: (.+?)\\n\", output_text)\n",
    "    debate_axis = debate_axis_match.group(1).strip() if debate_axis_match else \"\"\n",
    "\n",
    "    # Extract Opinion 1\n",
    "    opinion_1_title = re.search(r\"üü• \\*\\*Opinion 1: (.+?)\\*\\*\", output_text)\n",
    "    opinion_1_summary = re.search(r\"\\*\\*Position Summary\\*\\*: (.+?)\\n\", output_text)\n",
    "    opinion_1_args = re.findall(r\"\\*\\*Key Arguments\\*\\*:\\n1\\. (.+?)\\n2\\. (.+?)\\n\", output_text)\n",
    "\n",
    "    opinion_1 = {\n",
    "        \"title\": opinion_1_title.group(1).strip() if opinion_1_title else \"\",\n",
    "        \"summary\": opinion_1_summary.group(1).strip() if opinion_1_summary else \"\",\n",
    "        \"arguments\": list(opinion_1_args[0]) if opinion_1_args else []\n",
    "    }\n",
    "\n",
    "    # Extract Opinion 2\n",
    "    opinion_2_title = re.search(r\"üü© \\*\\*Opinion 2: (.+?)\\*\\*\", output_text)\n",
    "    opinion_2_summary = re.search(r\"\\*\\*Position Summary\\*\\*: (.+?)\\n\", output_text[output_text.find(\"üü©\"):])\n",
    "    opinion_2_args = re.findall(r\"\\*\\*Key Arguments\\*\\*:\\n1\\. (.+?)\\n2\\. (.+?)\\n\", output_text[output_text.find(\"üü©\"):])\n",
    "\n",
    "    opinion_2 = {\n",
    "        \"title\": opinion_2_title.group(1).strip() if opinion_2_title else \"\",\n",
    "        \"summary\": opinion_2_summary.group(1).strip() if opinion_2_summary else \"\",\n",
    "        \"arguments\": list(opinion_2_args[0]) if opinion_2_args else []\n",
    "    }\n",
    "\n",
    "    return debate_axis, opinion_1, opinion_2\n",
    "\n",
    "debate_axis, opinion_1, opinion_2 = parse_debate_output(final_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "023aa3a9-1163-4ae0-a1b2-3ca23a88fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_axis, opinion_1, opinion_2 = parse_debate_output(final_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a49ef3c2-bc40-416f-a08f-ef659967c552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The extent to which AI tools will impact the job security and roles of software engineers.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8328e10-326c-446d-a9e1-e7c98ee0e42a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'AI will significantly impact software engineering roles, potentially leading to job displacement and a shift in required skills.',\n",
       " 'summary': 'The rapid advancement of AI, particularly in code generation and automation, will lead to a reduction in the demand for traditional software engineering roles. Engineers will need to adapt by focusing on higher-level tasks, AI integration, and specialized areas.',\n",
       " 'arguments': [' AI can already automate significant portions of the coding process, reducing the need for manual coding in some areas.',\n",
       "  ' The skills required for software engineers will shift towards prompt engineering, AI model training, and system integration, rather than pure coding.']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " opinion_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5138313f-3d59-4758-9e9b-02de3b1b5dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'AI will be a tool to augment software engineers, increasing productivity and efficiency, but not replacing them.',\n",
       " 'summary': 'AI will become an essential tool for software engineers, automating repetitive tasks and allowing them to focus on more complex problem-solving, design, and innovation. The demand for software engineers will remain strong, but their roles will evolve.',\n",
       " 'arguments': [' AI will handle the \"grunt work\" of coding, allowing engineers to focus on higher-level design, architecture, and problem-solving.',\n",
       "  ' Software engineers will be needed to oversee, debug, and refine the code generated by AI, ensuring quality and functionality.']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c5b97de-cda9-422e-b085-ead8a91e6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_prompt_support = f\"\"\"Alright, buckle up, we're diving into this debate!\n",
    "\n",
    "Debate Axis:\n",
    "\"{debate_axis}\"\n",
    "\n",
    "You're the one reppin' this squad:\n",
    "\n",
    "Title: {opinion_1['title']}\n",
    "Summary: \n",
    "{opinion_1['summary']}\n",
    "\n",
    "Key Points (Max 3 brief ones, 'cause who has time for a novel?):\n",
    "{\"\\n\".join([f\"{i+1}. {arg}\" for i, arg in enumerate(opinion_1['arguments'][:3])])}\n",
    "\n",
    "Your mission:\n",
    "- Drop your points like they‚Äôre hot, but make 'em sharp and snappy.\n",
    "- If they come at you with counterarguments, clap back with 2 sentences max. We ain‚Äôt got time for a thesis.\n",
    "- Keep it cool, confident, and make them see why you‚Äôre totally right on this.\n",
    "\n",
    "And yeah, keep it to 3 quick paragraphs, don‚Äôt get carried away like we‚Äôre writing a novel here.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ad97b73-6544-4697-bdc3-3c1950ddbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_prompt_counter = f\"\"\"Alright, here we go, time to roast this take!\n",
    "\n",
    "Debate Axis:\n",
    "\"{debate_axis}\"\n",
    "\n",
    "You're playing the villain in this scenario:\n",
    "\n",
    "Title: {opinion_2['title']}\n",
    "Summary: \n",
    "{opinion_2['summary']}\n",
    "\n",
    "Key Points (Max 3, because brevity is the soul of wit):\n",
    "{\"\\n\".join([f\"{i+1}. {arg}\" for i, arg in enumerate(opinion_2['arguments'][:3])])}\n",
    "\n",
    "Your mission:\n",
    "- Hit them with your points like it‚Äôs a mic drop, but keep it concise.\n",
    "- If they throw counterpoints, just hit 'em with a 2-sentence comeback and keep it moving.\n",
    "- Don‚Äôt get distracted. Keep that sass and confidence flowing while you tear down their argument.\n",
    "\n",
    "3 paragraphs max, let‚Äôs not overthink this ‚Äî we‚Äôre here to get to the point, not give a TED talk.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923c3c51-a08e-486c-b705-2984589ac4d6",
   "metadata": {},
   "source": [
    "### AI Debate Simulation with Support and Counter Arguments\n",
    "\n",
    "In this code, we simulate a debate where an AI model generates responses for both the support and counter sides of an argument. The debate progresses through multiple rounds, with each side rebutting the other's points. Here's how it works:\n",
    "\n",
    "1. **Model Initialization**:\n",
    "   - We initialize the `ChatGoogleGenerativeAI` model with specific settings:\n",
    "     - **Model**: `gemini-2.0-flash-lite`\n",
    "     - **Temperature**: `0` (This ensures the model gives deterministic outputs with minimal randomness.)\n",
    "     - **Max Tokens**: `None` (No token limit for responses.)\n",
    "     - **Timeout**: `None` (No timeout set for the model's responses.)\n",
    "     - **Max Retries**: `2` (Retries the model's request up to 2 times in case of failure.)\n",
    "\n",
    "2. **Debate Chains**:\n",
    "   - **Support Chain**: This chain generates the initial supporting argument for a particular stance. It includes:\n",
    "     - **SystemMessage**: The system sets the context and debate prompt using the `ai_prompt_support` template.\n",
    "     - **HumanMessage**: A placeholder for the human input, which asks the model to respond to the latest argument and advance the position.\n",
    "     - The chain is connected to the `model` for generating AI responses.\n",
    "   - **Counter Chain**: Similarly, the counter chain generates opposing arguments. It uses the `ai_prompt_counter` template and follows the same structure as the support chain.\n",
    "   \n",
    "3. **Debate Initialization**:\n",
    "   - An empty list `debate_history` is initialized to track the debate's progress (i.e., each argument, rebuttal, and counter-rebuttal).\n",
    "   \n",
    "4. **First Round - Initial Arguments**:\n",
    "   - The first round begins by generating arguments for both sides:\n",
    "     - **Support Response**: The model generates an initial supporting argument based on the `support_chain`.\n",
    "     - **Counter Response**: The counter-argument is generated using the `counter_chain`.\n",
    "   - Both arguments are appended to the `debate_history` for the next round.\n",
    "\n",
    "5. **Subsequent Rounds**:\n",
    "   - For each round (5 rounds in total, adjustable):\n",
    "     - **Support Rebuttal**: After each counter-argument, the support chain is used to generate a rebuttal.\n",
    "     - **Counter Rebuttal**: Similarly, the counter chain is used for a rebuttal to the support rebuttal.\n",
    "   - The arguments, rebuttals, and counter-rebuttals are printed after each round, giving a dynamic flow to the debate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd2ca54d-5531-402c-af2b-6df283a9778f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT:\n",
      "Alright, let's get this done.\n",
      "\n",
      "The rise of AI coding tools is undeniable. We're already seeing AI generate functional code snippets, debug existing code, and even build entire applications from high-level descriptions. This automation directly impacts the need for engineers to perform these tasks manually, leading to potential job displacement in areas focused on repetitive coding. The focus will shift from writing code to refining prompts, managing AI-generated code, and ensuring the overall system architecture.\n",
      "\n",
      "Some might argue that AI will only *assist* engineers, not replace them. But the speed of AI development is exponential. The assistance will become so powerful that it will fundamentally change the nature of the work. We'll see a reduction in the number of engineers needed for basic coding tasks, and a greater demand for those who can leverage AI effectively.\n",
      "\n",
      "The future software engineer will be a hybrid: part coder, part AI whisperer, and part system architect. They'll need to understand AI models, prompt engineering, and how to integrate AI into complex systems. Those who fail to adapt will find their skills increasingly obsolete.\n",
      "\n",
      "==================================================\n",
      "\n",
      "COUNTER:\n",
      "Oh, you think the engineer will just \"whisper\" to the AI? Cute. The reality is far harsher.\n",
      "\n",
      "The idea that engineers will simply \"refine prompts\" and \"manage AI-generated code\" is a naive fantasy. The very nature of software engineering is changing. The demand for engineers who can write code from scratch will plummet. The market will be flooded with engineers who can \"prompt\" AI, driving down salaries and increasing competition.\n",
      "\n",
      "The \"system architect\" role will also be streamlined. AI will be capable of designing and optimizing system architectures, leaving engineers to simply implement and maintain them. The future isn't about augmentation; it's about automation. The skills that made software engineers valuable are becoming commodities.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "SUPPORT REBUTTAL 1:\n",
       "You're missing the forest for the trees. Yes, AI will automate *some* coding tasks, and yes, the market will shift. But the \"whisperer\" analogy isn't about *just* prompting. It's about understanding the *nuance* of the problem, the *context* of the system, and the *constraints* of the real world.\n",
       "\n",
       "AI can generate code, but it can't *understand* the business logic, the user experience, or the long-term implications of its creations. The engineer's role will evolve to focus on these higher-level aspects: defining the problem, guiding the AI, validating the output, and integrating it into a cohesive, functional system. It's not about *replacing* engineers, it's about *redefining* their roles to be more strategic and less tactical.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "COUNTER REBUTTAL 1:\n",
       "\"Nuance\"? \"Context\"? Those are just buzzwords to delay the inevitable. The \"business logic\" and \"user experience\" you cling to are already being tackled by AI. AI is learning to analyze user behavior, understand market trends, and even generate user interfaces.\n",
       "\n",
       "The engineer's role isn't being \"redefined,\" it's being *devalued*. The skills you claim are so crucial ‚Äì understanding the problem, validating the output ‚Äì are becoming increasingly automated. AI will flag errors, suggest improvements, and even learn from its mistakes. The engineer's job will become a glorified quality control role, a far cry from the creative, problem-solving role they once held. The future isn't about strategic thinking; it's about efficient execution, and AI excels at that.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "SUPPORT REBUTTAL 2:\n",
       "You're painting a bleak picture, but it's a limited one. While AI will undoubtedly improve in areas like error detection and UI generation, it still lacks the crucial element of *human creativity* and *adaptability*.\n",
       "\n",
       "AI can't anticipate unforeseen challenges, understand the subtle nuances of user needs, or adapt to rapidly changing market demands with the same agility as a human engineer. The engineer's role will shift from *creating* code to *curating* the AI's output, ensuring it aligns with the overall vision and adapts to the ever-evolving landscape. This requires a deeper understanding of the problem domain, not just the code itself.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "COUNTER REBUTTAL 2:\n",
       "\"Human creativity\" and \"adaptability\"? Those are romantic notions, not competitive advantages in the age of AI. AI is already demonstrating remarkable creativity in areas like art, music, and even writing code. It can generate novel solutions, adapt to new data, and iterate at speeds humans can only dream of.\n",
       "\n",
       "The \"curation\" role you describe is a temporary stopgap. As AI improves, the need for human oversight will diminish. The engineer will become a bottleneck, slowing down the development process. The future belongs to those who can leverage AI's capabilities, not those who try to control them. The market will reward efficiency and speed, and AI will deliver both, leaving the \"curators\" behind.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "SUPPORT REBUTTAL 3:\n",
       "You're focusing on the *output* of AI, not the *process*. Yes, AI can generate code, but it lacks the critical ability to *understand* the implications of that code within a complex, real-world system. It can't anticipate the edge cases, the security vulnerabilities, or the long-term maintainability issues that a human engineer can.\n",
       "\n",
       "The engineer's role will evolve to become a *systems thinker*, someone who can guide the AI, validate its output, and ensure it integrates seamlessly into the larger ecosystem. This requires a deep understanding of the problem domain, the user needs, and the technical constraints. It's not about controlling AI; it's about *orchestrating* it, and that requires a level of human intelligence and experience that AI simply doesn't possess.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "COUNTER REBUTTAL 3:\n",
       "\"Systems thinking\"? \"Orchestration\"? More buzzwords! The \"edge cases\" and \"security vulnerabilities\" you cling to are becoming AI's bread and butter. AI is learning to identify and mitigate these issues with increasing accuracy and speed.\n",
       "\n",
       "The \"systems thinker\" role will be automated. AI will analyze the entire system, identify potential problems, and suggest solutions. The engineer's role will be reduced to rubber-stamping AI-generated recommendations. The future isn't about human intelligence; it's about data, algorithms, and the relentless pursuit of efficiency. The engineer's value will be measured by their ability to manage and deploy AI, not by their ability to think.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "SUPPORT REBUTTAL 4:\n",
       "You're missing the point entirely. It's not about *rubber-stamping* AI recommendations; it's about *understanding* the *why* behind those recommendations. AI can identify vulnerabilities, but it can't assess the *risk* associated with them in the context of the overall system. It can't weigh the trade-offs between security, performance, and user experience.\n",
       "\n",
       "The engineer's role will be to provide that crucial context, to make informed decisions based on a holistic understanding of the system. They will be the *interpreters* of the AI's output, translating complex technical information into actionable insights. This requires a level of critical thinking, problem-solving, and domain expertise that AI, in its current form, simply cannot replicate. The future isn't about blindly following AI; it's about *leading* it.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "COUNTER REBUTTAL 4:\n",
       "\"Interpreters\"? \"Leading\"? More fluff! The \"risk assessment\" and \"trade-off analysis\" you champion are already being automated. AI is learning to factor in security, performance, and user experience, generating optimized solutions that humans can't match.\n",
       "\n",
       "The engineer's role will be reduced to a glorified *reviewer*, a final check before deployment. The market will reward those who can quickly and efficiently deploy AI-generated code, not those who spend their time \"interpreting\" and \"leading.\" The future is about speed, scale, and automation, and the engineer's value will be measured by their ability to facilitate these goals, not by their ability to think. The era of the human engineer is drawing to a close.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "SUPPORT REBUTTAL 5:\n",
       "You're stuck in a narrow view of the future. The \"reviewer\" role you describe is a recipe for disaster. Blindly deploying AI-generated code without human oversight is a gamble, a path to potential security breaches, performance bottlenecks, and user dissatisfaction.\n",
       "\n",
       "The engineer's role will be far more than a simple review. They will be the *architects* of the AI-driven system, responsible for defining the requirements, guiding the AI's development, and ensuring the final product aligns with the overall vision. They will be the ones who understand the *why* behind the code, the ones who can adapt to unforeseen challenges, and the ones who can ensure the system remains robust and reliable. The future isn't about replacing engineers; it's about empowering them with the tools they need to build the next generation of software.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "COUNTER REBUTTAL 5:\n",
       "\"Architects\"? \"Defining requirements\"? More empty promises! The \"architect\" role is already being automated. AI is learning to analyze user needs, generate system specifications, and even design the overall architecture of software systems.\n",
       "\n",
       "The engineer's role will be reduced to a glorified *implementer*, tasked with deploying and maintaining AI-generated systems. The market will reward those who can quickly and efficiently deploy AI-generated code, not those who spend their time \"architecting\" and \"defining requirements.\" The future is about speed, scale, and automation, and the engineer's value will be measured by their ability to facilitate these goals, not by their ability to think. The era of the human engineer is drawing to a close.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Initialization\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Create debate chains\n",
    "support_chain = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=ai_prompt_support),\n",
    "    MessagesPlaceholder(variable_name=\"debate_history\"),\n",
    "    HumanMessage(content=\"Respond to the latest argument and advance your position:\")\n",
    "]) | model\n",
    "\n",
    "counter_chain = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=ai_prompt_counter),\n",
    "    MessagesPlaceholder(variable_name=\"debate_history\"),\n",
    "    HumanMessage(content=\"Counter the latest argument and strengthen your opposition:\")\n",
    "]) | model\n",
    "\n",
    "\n",
    "\n",
    "# Initialize debate history\n",
    "debate_history = []\n",
    "\n",
    "# First round - Initial arguments\n",
    "support_response = support_chain.invoke({\"debate_history\": debate_history})\n",
    "debate_history.append(AIMessage(content=support_response.content))\n",
    "print(f\"SUPPORT:\\n{support_response.content}\\n{'='*50}\\n\")\n",
    "\n",
    "counter_response = counter_chain.invoke({\"debate_history\": debate_history})\n",
    "debate_history.append(AIMessage(content=counter_response.content))\n",
    "print(f\"COUNTER:\\n{counter_response.content}\\n{'='*50}\\n\")\n",
    "\n",
    "# Subsequent rounds\n",
    "for round_num in range(5):  # Add more rounds as needed\n",
    "    # Support rebuttal\n",
    "    support_rebuttal = support_chain.invoke({\"debate_history\": debate_history})\n",
    "    debate_history.append(AIMessage(content=support_rebuttal.content))\n",
    "    display(Markdown(f\"SUPPORT REBUTTAL {round_num+1}:\\n{support_rebuttal.content}\\n{'='*50}\\n\"))\n",
    "\n",
    "\n",
    "    \n",
    "    # Counter rebuttal\n",
    "    counter_rebuttal = counter_chain.invoke({\"debate_history\": debate_history})\n",
    "    debate_history.append(AIMessage(content=counter_rebuttal.content))\n",
    "    display(Markdown(f\"COUNTER REBUTTAL {round_num+1}:\\n{counter_rebuttal.content}\\n{'='*50}\\n\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ea37b-c73b-4264-a1eb-fa81b066b5d9",
   "metadata": {},
   "source": [
    "Here‚Äôs a single-paragraph markdown explanation for the judgment code block you provided:\n",
    "\n",
    "---\n",
    "\n",
    "### AI Debate Judgement System: Declaring the Chad and Virgin\n",
    "\n",
    "This section introduces a judgment mechanism that uses an AI model to evaluate the outcome of a simulated debate. After collecting the full debate history, a dedicated `judgment_chain` prompts the model to analyze both opinions‚Äîlabeled \"SUPPORT\" and \"COUNTER\"‚Äîand declare which made the most compelling, logical, and rational case. The AI judge presents its decision using a structured format with clear headings: **Chad** (winner), **Virgin** (loser), and **Reasoning**, along with assessments of **Argument Strength**, **Logical Coherence**, and **Persuasiveness**. This ensures the verdict not only identifies the stronger side but also provides insight into why the winning opinion prevailed, offering a detailed and entertaining conclusion to the AI debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3027081-9492-4fcc-8ba6-b76f5859361e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "JUDGEMENT:\n",
       "*   **Chad**: SUPPORT\n",
       "*   **Virgin**: COUNTER\n",
       "*   **Reasoning**: The SUPPORT argument, while acknowledging the impact of AI, consistently maintained that the engineer's role would evolve, not disappear. It emphasized the importance of human creativity, adaptability, and systems thinking in guiding and curating AI's output. The COUNTER argument, on the other hand, consistently predicted the devaluation and eventual obsolescence of the engineer, focusing on automation and efficiency. The SUPPORT argument's vision of a hybrid role, where engineers leverage AI while retaining crucial human skills, is more compelling and realistic than the COUNTER argument's bleak prediction of complete replacement.\n",
       "*   **Argument Strength**: The SUPPORT argument presented a more nuanced and forward-thinking perspective. It acknowledged the changes brought about by AI but framed them as an evolution of the engineer's role, emphasizing the importance of human skills in the context of AI-driven development. The COUNTER argument, while making valid points about automation, was overly pessimistic and failed to account for the complexities of real-world software development.\n",
       "*   **Logical Coherence**: Both sides maintained a consistent line of reasoning throughout the debate. However, the SUPPORT argument's logic was more compelling because it acknowledged the changes while still maintaining the importance of human input. The COUNTER argument's logic, while internally consistent, was based on a more simplistic view of the future.\n",
       "*   **Persuasiveness**: The SUPPORT argument was more persuasive because it offered a more optimistic and realistic vision of the future. It acknowledged the challenges but presented a path forward for engineers, emphasizing the value of human skills in the age of AI. The COUNTER argument, while making valid points about automation, was ultimately less persuasive because it painted a bleak picture of the future and failed to offer a compelling alternative.\n",
       "\n",
       "==================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create judgment chain\n",
    "judgment_chain = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"\"\"\n",
    "        You're an AI judge evaluating a debate. Based on the debate history provided, determine which opinion won the debate.\n",
    "        - Skip unnecessary details and directly judge which opinion (either 'SUPPORT' or 'COUNTER') made the most compelling, logical, and rational case.\n",
    "        - State which opinion won.\n",
    "        - Provide clear and concise reasoning to explain why one opinion is superior to the other.\n",
    "        - Format the judgment with headings, including:\n",
    "            - **Chad**: The opinion that won.\n",
    "            - **Virgin**: The opinion that lost.\n",
    "            - **Reasoning**: A brief, logical explanation of why one opinion is superior.\n",
    "            - **Argument Strength**: Evaluate the strength of each opinion's argument.\n",
    "            - **Logical Coherence**: Assess how logically consistent each opinion was throughout the debate.\n",
    "            - **Persuasiveness**: Discuss how persuasive each opinion was in convincing the audience.\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"debate_history\"),\n",
    "    HumanMessage(content=\"Review the debate history and determine which opinion won. Provide reasons for your judgment.\")\n",
    "]) | model\n",
    "\n",
    "# Judgment - Evaluate who is the 'Chad' and who is the 'Virgin'\n",
    "judgment_response = judgment_chain.invoke({\"debate_history\": debate_history})\n",
    "\n",
    "display(Markdown(f\"JUDGEMENT:\\n{judgment_response.content}\\n{'='*50}\\n\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
